{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "labelme2coco.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORAUNKmDTu+iYw8uPyd3NN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moey920/Object-Detection/blob/master/labelme2coco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnP5nc12jdK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import collections\n",
        "import datetime\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import os.path as osp\n",
        "import sys\n",
        "import uuid\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "import labelme\n",
        "\n",
        "try:\n",
        "    import pycocotools.mask\n",
        "except ImportError:\n",
        "    print(\"Please install pycocotools:\\n\\n    pip install pycocotools\\n\")\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
        "    )\n",
        "    parser.add_argument(\"input_dir\", help=\"input annotated directory\")\n",
        "    parser.add_argument(\"output_dir\", help=\"output dataset directory\")\n",
        "    parser.add_argument(\"--labels\", help=\"labels file\", required=True)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if osp.exists(args.output_dir):\n",
        "        print(\"Output directory already exists:\", args.output_dir)\n",
        "        sys.exit(1)\n",
        "    os.makedirs(args.output_dir)\n",
        "    os.makedirs(osp.join(args.output_dir, \"JPEGImages\"))\n",
        "    print(\"Creating dataset:\", args.output_dir)\n",
        "\n",
        "    now = datetime.datetime.now()\n",
        "\n",
        "    data = dict(\n",
        "        info=dict(\n",
        "            description=None,\n",
        "            url=None,\n",
        "            version=None,\n",
        "            year=now.year,\n",
        "            contributor=None,\n",
        "            date_created=now.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n",
        "        ),\n",
        "        licenses=[dict(url=None, id=0, name=None,)],\n",
        "        images=[\n",
        "            # license, url, file_name, height, width, date_captured, id\n",
        "        ],\n",
        "        type=\"instances\",\n",
        "        annotations=[\n",
        "            # segmentation, area, iscrowd, image_id, bbox, category_id, id\n",
        "        ],\n",
        "        categories=[\n",
        "            # supercategory, id, name\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    class_name_to_id = {}\n",
        "    for i, line in enumerate(open(args.labels).readlines()):\n",
        "        class_id = i - 1  # starts with -1\n",
        "        class_name = line.strip()\n",
        "        if class_id == -1:\n",
        "            assert class_name == \"__ignore__\"\n",
        "            continue\n",
        "        class_name_to_id[class_name] = class_id\n",
        "        data[\"categories\"].append(\n",
        "            dict(supercategory=None, id=class_id, name=class_name,)\n",
        "        )\n",
        "\n",
        "    out_ann_file = osp.join(args.output_dir, \"annotations.json\")\n",
        "    label_files = glob.glob(osp.join(args.input_dir, \"*.json\"))\n",
        "    for image_id, filename in enumerate(label_files):\n",
        "        print(\"Generating dataset from:\", filename)\n",
        "\n",
        "        label_file = labelme.LabelFile(filename=filename)\n",
        "\n",
        "        base = osp.splitext(osp.basename(filename))[0]\n",
        "        out_img_file = osp.join(args.output_dir, \"JPEGImages\", base + \".jpg\")\n",
        "\n",
        "        img = labelme.utils.img_data_to_arr(label_file.imageData)\n",
        "        PIL.Image.fromarray(img).convert(\"RGB\").save(out_img_file)\n",
        "        data[\"images\"].append(\n",
        "            dict(\n",
        "                license=0,\n",
        "                url=None,\n",
        "                file_name=osp.relpath(out_img_file, osp.dirname(out_ann_file)),\n",
        "                height=img.shape[0],\n",
        "                width=img.shape[1],\n",
        "                date_captured=None,\n",
        "                id=image_id,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        masks = {}  # for area\n",
        "        segmentations = collections.defaultdict(list)  # for segmentation\n",
        "        for shape in label_file.shapes:\n",
        "            points = shape[\"points\"]\n",
        "            label = shape[\"label\"]\n",
        "            group_id = shape.get(\"group_id\")\n",
        "            shape_type = shape.get(\"shape_type\", \"polygon\")\n",
        "            mask = labelme.utils.shape_to_mask(\n",
        "                img.shape[:2], points, shape_type\n",
        "            )\n",
        "\n",
        "            if group_id is None:\n",
        "                group_id = uuid.uuid1()\n",
        "\n",
        "            instance = (label, group_id)\n",
        "\n",
        "            if instance in masks:\n",
        "                masks[instance] = masks[instance] | mask\n",
        "            else:\n",
        "                masks[instance] = mask\n",
        "\n",
        "            if shape_type == \"rectangle\":\n",
        "                (x1, y1), (x2, y2) = points\n",
        "                x1, x2 = sorted([x1, x2])\n",
        "                y1, y2 = sorted([y1, y2])\n",
        "                points = [x1, y1, x2, y1, x2, y2, x1, y2]\n",
        "            else:\n",
        "                points = np.asarray(points).flatten().tolist()\n",
        "\n",
        "            segmentations[instance].append(points)\n",
        "        segmentations = dict(segmentations)\n",
        "\n",
        "        for instance, mask in masks.items():\n",
        "            cls_name, group_id = instance\n",
        "            if cls_name not in class_name_to_id:\n",
        "                continue\n",
        "            cls_id = class_name_to_id[cls_name]\n",
        "\n",
        "            mask = np.asfortranarray(mask.astype(np.uint8))\n",
        "            mask = pycocotools.mask.encode(mask)\n",
        "            area = float(pycocotools.mask.area(mask))\n",
        "            bbox = pycocotools.mask.toBbox(mask).flatten().tolist()\n",
        "\n",
        "            data[\"annotations\"].append(\n",
        "                dict(\n",
        "                    id=len(data[\"annotations\"]),\n",
        "                    image_id=image_id,\n",
        "                    category_id=cls_id,\n",
        "                    segmentation=segmentations[instance],\n",
        "                    area=area,\n",
        "                    bbox=bbox,\n",
        "                    iscrowd=0,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    with open(out_ann_file, \"w\") as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}